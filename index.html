<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Machine Learning Algorithms and Their Applications</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      line-height: 1.6;
    }
    h1, h2 {
      color: #2c3e50;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 20px;
    }
    th, td {
      border: 1px solid #ddd;
      padding: 8px;
      vertical-align: top;
    }
    th {
      background-color: #f2f2f2;
    }
    .abstract, .reflection {
      margin-top: 20px;
      padding: 10px;
      background-color: #f9f9f9;
      border-left: 5px solid #3498db;
    }
  </style>
</head>
<body>

  <h1>Machine Learning Algorithms and Their Applications Across Domains</h1>
  <p><strong>Mohammad Anwar Karim</strong><br>
  AIML-501 Model Development<br>
 
  05/15/2025</p>

  <h2>Abstract</h2>
  <div class="abstract">
    This portfolio artifact provides a visual and conceptual overview of key machine learning algorithms and their primary application domains, including tabular data, computer vision, natural language processing (NLP), and generative AI. The artifact contains ten widely used algorithms organized by learning style (supervised or unsupervised), real-world examples, and a brief explanation of how each algorithm works. The reflection discusses the learning outcomes and relevance of algorithm selection in real-world AI applications.  </div>

  <h2>Visual Framework Description</h2>
  <p>The infographic visually categorizes ten machine learning algorithms by type (supervised or unsupervised) and assigns them to four major AI domains: tabular data, computer vision, natural language processing, and generative AI. Each algorithm entry contains:
<ul>
    <li><strong>Algorithm Type:</strong> Supervised or Unsupervised</li>
    <li><strong>Application Domain(s):</strong> One or more applicable areas</li>
    <li><strong>Real-World Example:</strong> Practical use case</li>
    <li><strong>How It Works:</strong> Summary of the core mechanism</li>
  </ul>
  <p>The infographic color-codes learning types (blue for supervised, orange for unsupervised) and represents domains with icons (e.g., table for tabular data, eye for CV). Arrows represent relationships or progression paths (for example, PCA frequently precedes supervised classification).
<h2>Visual Framework Infographic</h2>
  <img src="infographic.jpg" alt="ML Algorithm Infographic" width="100%" />
  <h2>Algorithms Overview Table</h2>
  <table>
    <thead>
      <tr>
        <th>Algorithm</th>
        <th>Type</th>
        <th>Domains</th>
        <th>Use Case</th>
        <th>Explanation</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Decision Tree</td>
        <td>Supervised</td>
        <td>Tabular</td>
        <td>Credit risk classification</td>
        <td>Splits data at decision points based on features.</td>
      </tr>
      <tr>
        <td>Random Forest</td>
        <td>Supervised</td>
        <td>Tabular, CV</td>
        <td>Fraud detection</td>
        <td>Combines many decision trees for better accuracy.</td>
      </tr>
      <tr>
        <td>Support Vector Machine</td>
        <td>Supervised</td>
        <td>Tabular, CV</td>
        <td>Email spam filtering</td>
        <td>Finds optimal margin between classes.</td>
      </tr>
      <tr>
        <td>Gradient Boosting</td>
        <td>Supervised</td>
        <td>Tabular</td>
        <td>Sales forecasting</td>
        <td>Learns from errors in sequential models.</td>
      </tr>
      <tr>
        <td>K-Means Clustering</td>
        <td>Unsupervised</td>
        <td>Tabular</td>
        <td>Customer segmentation</td>
        <td>Groups data into clusters based on distance.</td>
      </tr>
      <tr>
        <td>Principal Component Analysis</td>
        <td>Unsupervised</td>
        <td>Tabular, CV</td>
        <td>Data compression</td>
        <td>Reduces dimensionality while retaining variance.</td>
      </tr>
      <tr>
        <td>Convolutional Neural Network</td>
        <td>Supervised</td>
        <td>CV</td>
        <td>Image recognition</td>
        <td>Extracts visual patterns through filters.</td>
      </tr>
      <tr>
        <td>Transformer (e.g., BERT, GPT)</td>
        <td>Supervised</td>
        <td>NLP</td>
        <td>Text summarization</td>
        <td>Uses attention to understand sequence context.</td>
      </tr>
      <tr>
        <td>Generative Adversarial Network (GAN)</td>
        <td>Unsupervised</td>
        <td>Generative AI</td>
        <td>Deepfake generation</td>
        <td>Competing networks generate and validate outputs.</td>
      </tr>
      <tr>
        <td>Diffusion Models</td>
        <td>Unsupervised</td>
        <td>Generative AI</td>
        <td>AI art generation</td>
        <td>Reconstructs images from noise using probability.</td>
      </tr>
    </tbody>
  </table>

  <h2>Reflection</h2>
  <div class="reflection">
    Creating this portfolio product allowed me to synthesize my expertise of numerous machine learning algorithms and how they are utilized across domains. By categorizing them visually and textually, I was able to clearly show how algorithm choice depends on data type, learning goals, and task complexity. I learned more about why convolutional neural networks dominate vision challenges while transformer-based models changed language understanding. Furthermore, generative models such as GANs and diffusion models demonstrated the inventive potential of AI in content creation. This artifact strengthens my career portfolio by demonstrating both technical understanding and the ability to articulate complicated concepts effectivelyâ€”essential for any role in data science or AI.
 </div>

  <h2>References</h2>
  <ul>
    <li>Brownlee, J. (2020). <i>Machine Learning Algorithms From Scratch</i>. Machine Learning Mastery.</li>
    <li>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <i>Deep Learning</i>. MIT Press.</li>
    <li>Vaswani, A., et al. (2017). Attention is All You Need. <i>Advances in Neural Information Processing Systems, 30</i>.</li>
  </ul>

</body>
</html>
